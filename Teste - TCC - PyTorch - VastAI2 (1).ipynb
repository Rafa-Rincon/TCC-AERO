{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c5df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2704be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a27d8a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEMBRAR DE ADAPTAR OS DATASETS DOS AIRFOILS TB\n",
    "\n",
    "df = pd.read_excel('X3neg.xlsx', engine='openpyxl')\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "start_idx = cols.index('y_upper_1')\n",
    "end_idx = cols.index('y_lower_148') + 1 \n",
    "X = df.loc[:, cols[start_idx:end_idx]]\n",
    "\n",
    "# Parameterization 2: \n",
    "df2 = pd.read_excel('X_c3neg.xlsx', engine='openpyxl')\n",
    "X_c = df2[df2.columns[1:]]\n",
    "\n",
    "# Parameterization 3: \n",
    "df3 = pd.read_excel('X_d3neg.xlsx', engine='openpyxl')\n",
    "X_d = df3[df3.columns[1:]]\n",
    "\n",
    "# Parameterization 4:\n",
    "df4 = pd.read_excel('X_dc3neg.xlsx', engine = 'openpyxl')\n",
    "X_dc = df4[df4.columns[1:]]\n",
    "\n",
    "# Parameterization 5: \n",
    "df5 = pd.read_excel('X_p3neg.xlsx', engine = 'openpyxl')\n",
    "X_p = df5.iloc[:, 1:]\n",
    "\n",
    "# Parameterization 6: \n",
    "df6 = pd.read_excel('X_f3neg.xlsx', engine = 'openpyxl')\n",
    "X_f = df6.iloc[:, 1:]\n",
    "\n",
    "# Parameterization 7: \n",
    "df7 = pd.read_excel('X_k3neg.xlsx', engine = 'openpyxl')\n",
    "X_k = df7.iloc[:, :-1]\n",
    "\n",
    "# Parameterization 8: \n",
    "df8 = pd.read_excel('X_parsec3neg.xlsx', engine = 'openpyxl')\n",
    "X_parsec = df8.iloc[:, 1:]\n",
    "\n",
    "# Y\n",
    "df_y = pd.read_excel('CL_3neg_transformed.xlsx', engine = 'openpyxl')\n",
    "y = df_y['CL'] # Note that this will be the \"y\" for all the others ML trainments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "055f9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo pra tensores\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5978d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor_c = torch.tensor(X_c.values, dtype=torch.float32)\n",
    "X_tensor_d = torch.tensor(X_d.values, dtype=torch.float32)\n",
    "X_tensor_dc = torch.tensor(X_dc.values, dtype=torch.float32)\n",
    "X_tensor_p = torch.tensor(X_p.values, dtype=torch.float32)\n",
    "X_tensor_f = torch.tensor(X_f.values, dtype=torch.float32)\n",
    "X_tensor_k = torch.tensor(X_k.values, dtype=torch.float32)\n",
    "X_tensor_parsec = torch.tensor(X_parsec.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34f27f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1512, 16])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor_parsec.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "744a084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cf4eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet1, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "class NeuralNet3(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet3, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 48),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(48, 48),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(48, 48),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(48, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class NeuralNet4(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet4, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class NeuralNet5(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet5, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class NeuralNet6(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet6, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class NeuralNet7(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet7, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "\n",
    "class NeuralNet8(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet8, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class NeuralNet9(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet9, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8046da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss and optimizer here for easy reuse\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train_and_evaluate_model(model, train_loader, test_loader, epochs=1000, lr=0.0001):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            # 3. Move the data to GPU\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    mse_list, mae_list, mape_list = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            # 3. Move the data to GPU\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            predictions = model(batch_x)\n",
    "            mse = criterion(predictions, batch_y)\n",
    "            mae = torch.mean(torch.abs(predictions - batch_y))\n",
    "            mape = torch.mean(torch.abs((batch_y - predictions) / batch_y)) * 100\n",
    "            mse_list.append(mse.item())\n",
    "            mae_list.append(mae.item())\n",
    "            mape_list.append(mape.item())\n",
    "\n",
    "    return np.mean(mse_list), np.mean(mae_list), np.mean(mape_list)\n",
    "\n",
    "def cross_validate_neural_nets(X, y, k_folds=10):\n",
    "    dataset = TensorDataset(X, y)  # Create a single dataset\n",
    "    \n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    architectures = [NeuralNet1, NeuralNet2, NeuralNet3, NeuralNet4, NeuralNet5, NeuralNet6, NeuralNet7, NeuralNet8, NeuralNet9]\n",
    "    \n",
    "    overall_mse, overall_mae, overall_mape = [], [], []\n",
    "    \n",
    "    for arch_num, NeuralNetArch in enumerate(architectures):\n",
    "        print(f\"Training Architecture {arch_num + 1}\")\n",
    "        mse_values, mae_values, mape_values = [], [], []\n",
    "        \n",
    "        for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "            print(f\"Fold {fold + 1}\")\n",
    "            \n",
    "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "            test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "            \n",
    "            # Use more workers and pin_memory=True for faster data loading\n",
    "            trainloader = DataLoader(dataset, batch_size=128, sampler=train_subsampler, num_workers=0, pin_memory=False)\n",
    "            testloader = DataLoader(dataset, batch_size=128, sampler=test_subsampler, num_workers=0, pin_memory=False)\n",
    "            \n",
    "            model = NeuralNetArch(X.shape[1])\n",
    "            model = model.to(device)  # Move the model to GPU\n",
    "            \n",
    "            mse, mae, mape = train_and_evaluate_model(model, trainloader, testloader)\n",
    "            \n",
    "            mse_values.append(mse)\n",
    "            mae_values.append(mae)\n",
    "            mape_values.append(mape)\n",
    "        \n",
    "        architecture_mean_mse = np.mean(mse_values)\n",
    "        architecture_mean_mae = np.mean(mae_values)\n",
    "        architecture_mean_mape = np.mean(mape_values)\n",
    "        \n",
    "        results[f\"Architecture {arch_num + 1}\"] = {\n",
    "            \"MSE\": architecture_mean_mse,\n",
    "            \"MAE\": architecture_mean_mae,\n",
    "            \"MAPE\": architecture_mean_mape\n",
    "        }\n",
    "        \n",
    "        overall_mse.append(architecture_mean_mse)\n",
    "        overall_mae.append(architecture_mean_mae)\n",
    "        overall_mape.append(architecture_mean_mape)\n",
    "    \n",
    "    results[\"Overall\"] = {\n",
    "        \"MSE\": np.mean(overall_mse),\n",
    "        \"MAE\": np.mean(overall_mae),\n",
    "        \"MAPE\": np.mean(overall_mape)\n",
    "    }\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629aa7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Architecture 1\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "Fold 10\n",
      "Training Architecture 2\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "Fold 10\n"
     ]
    }
   ],
   "source": [
    "results = cross_validate_neural_nets(X_tensor, y_tensor)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b4a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
